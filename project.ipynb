{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Section 1: Problem Formulation\n",
    "\n",
    "### Introduction:\n",
    "In this project, we aim to explore the effectiveness of contrastive learning, specifically using the SimCLR algorithm, \n",
    "for image classification tasks under the constraint of having limited labeled data. Contrastive learning is a technique \n",
    "in self-supervised learning that learns to encode similar items closer in the feature space while pushing dissimilar items further apart.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "# Check if CUDA is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"dataset\": \"cifar10\",\n",
    "    \"model\": \"resnet18\",\n",
    "    \"batch_size\": 1024,\n",
    "    \"epochs\": 100,\n",
    "    \"n_views\": 2,\n",
    "    \"out_dim\": 128,\n",
    "    \"lr\": 12e-4,\n",
    "    \"log_every_n_steps\": 50,\n",
    "    \"n_workers\": 12,\n",
    "    \"temperature\": 0.5,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Dataset Preparations\n",
    "\n",
    "In this section, we will prepare the CIFAR-10, CIFAR-100, and MedMNIST datasets for training. \n",
    "We will apply necessary transformations and split the datasets into training, validation, and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\levscaut\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 24 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "from dataset import SimCLRDataset\n",
    "data = SimCLRDataset(args[\"dataset\"])\n",
    "train_dataset = data.get_dataset(n_views=args[\"n_views\"])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=args[\"batch_size\"], \n",
    "    num_workers=args[\"n_workers\"],\n",
    "    shuffle=True, \n",
    "    drop_last=True, \n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Deep Learning Model\n",
    "\n",
    "In this section, we will prepare the popular choice of deep learning model like ResNet18 and VGG16.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import SimCLRCNN \n",
    "model = SimCLRCNN(backbone=args[\"model\"], out_dim=args[\"out_dim\"])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Contrastive Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import metric, info_nce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [01:52<00:00,  2.34s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tLoss: 7.526223182678223\tTop1 accuracy: 0.29296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_iter = 0\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "\n",
    "for epoch_counter in range(args['epochs']):\n",
    "\n",
    "    for images, _ in tqdm(train_loader):\n",
    "        images = torch.cat(images, dim=0)\n",
    "        images = images.to(device)\n",
    "        features = model(images)\n",
    "        logits, labels = info_nce_loss(features, device, args)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if n_iter % args['log_every_n_steps'] == 0:\n",
    "            top1, top5 = metric(logits, labels, topk=(1, 5))\n",
    "\n",
    "        n_iter += 1\n",
    "\n",
    "    print(f\"Epoch: {epoch_counter}\\tLoss: {loss}\\tTop1 accuracy: {top1[0]}\")\n",
    "\n",
    "print(\"Training has finished.\")\n",
    "# save model checkpoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uoft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
